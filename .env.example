# =====================================================
# AI Talent Matcher - Backend Configuration
# =====================================================

# ===== LLM Provider Configuration =====
# Choose your LLM provider: openai, gemini, anthropic, or ollama
LLM_PROVIDER=openai

# ----- OpenAI Configuration -----
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview
# Other options: gpt-4, gpt-3.5-turbo, gpt-4-1106-preview

# ----- Google Gemini Configuration -----
# Get your API key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_MODEL=gemini-pro
# Other options: gemini-pro-vision

# ----- Anthropic Configuration -----
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-opus-20240229
# Other options: claude-3-sonnet-20240229, claude-3-haiku-20240307

# ----- Ollama Configuration (Local LLM) -----
# Run Ollama locally: https://ollama.ai/
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2
# Other options: mistral, mixtral, codellama, etc.

# ===== LLM Parameters =====
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=2000
LLM_TIMEOUT=60

# ===== Scoring Configuration =====
# Weights must sum to 1.0
SIMILARITY_WEIGHT=0.6
MUST_HAVE_BOOST_WEIGHT=0.3
RECENCY_BOOST_WEIGHT=0.1

# ===== Storage Configuration =====
STORAGE_TYPE=local
STORAGE_PATH=./data/storage

# ===== Cache Configuration =====
ENABLE_CACHE=true
CACHE_PATH=./data/cache
CACHE_EMBEDDINGS=true
CACHE_LLM_RESPONSES=true
CACHE_SCORES=true
CACHE_TTL=2592000

# ===== Output Configuration =====
OUTPUT_DIR=./data/output
CSV_ENCODING=utf-8

# ===== Prompt Configuration =====
PROMPTS_DIR=./src/prompts

# ===== Data Paths =====
RESUMES_RAW_DIR=./data/resumes/raw
RESUMES_PROCESSED_DIR=./data/resumes/processed
JD_RAW_DIR=./data/job_descriptions/raw
JD_PROCESSED_DIR=./data/job_descriptions/processed
